{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Family Regressions\n",
    "\n",
    "In this notebook, we mainly produce Figure 6 and the analogue figures in the SI.\n",
    "We also compile the regression statistics table reported in the SI.\n",
    "\n",
    "For all figures, we use the connected components of the Cluster Family Graph and name each of them by the largest single node contained in it."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run de_hue_order_alignment.py\n",
    "\n",
    "from collections import defaultdict\n",
    "import functools\n",
    "from scipy import stats\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend import Legend\n",
    "import seaborn as sns\n",
    "\n",
    "from legal_data_clustering.utils.graph_api import cluster_families\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['axes.formatter.limits'] = (-10, 10) # for consistently non-scientific notation\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_manual_labels(dataset):\n",
    "    df = pd.read_csv(f'../graphics/labels-{dataset.lower()}.csv')\n",
    "    return {cluster: label for cluster, label in zip(df['Cluster ID'], df['Label'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def subtitle_decorator(handler):\n",
    "    @functools.wraps(handler)\n",
    "    def wrapper(legend, orig_handle, fontsize, handlebox):\n",
    "        handle_marker = handler(legend, orig_handle, fontsize, handlebox)\n",
    "        if handle_marker.get_alpha() == 0:\n",
    "            handlebox.set_visible(False)\n",
    "    return wrapper\n",
    "\n",
    "# Adds our decorator to all legend handler functions\n",
    "for handler in Legend.get_default_handler_map().values():\n",
    "    handler.legend_artist = subtitle_decorator(handler.legend_artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_edges(G, threshold):\n",
    "    edges_to_remove = [\n",
    "        (u, v) \n",
    "        for u, v, data in G.edges(data=True) \n",
    "        if (\n",
    "            data['weight'] < G.nodes[u]['weight'] * threshold or\n",
    "            data['weight'] < G.nodes[v]['weight'] * threshold \n",
    "        )\n",
    "    ]\n",
    "    H = G.copy()\n",
    "    H.remove_edges_from(edges_to_remove)\n",
    "    return H\n",
    "\n",
    "\n",
    "def count_weight_per_year(nodes_set, H):\n",
    "    counts = defaultdict(int)\n",
    "    for node in nodes_set:\n",
    "        year = node.split('_')[0]\n",
    "        counts[year] += H.nodes[node]['weight']\n",
    "    return dict(counts)\n",
    "\n",
    "\n",
    "def get_connected_components_per_year(H):\n",
    "    components = list(nx.connected_components(H.to_undirected()))\n",
    "    components.sort(\n",
    "        key=lambda nodes_set: (max([H.nodes[n][\"tokens_n\"] for n in nodes_set]), sorted(nodes_set)[-1]),\n",
    "        reverse=True\n",
    "    )\n",
    "    component_weight_per_year = [\n",
    "        count_weight_per_year(nodes_set, H)\n",
    "        for nodes_set in components\n",
    "    ]\n",
    "    return component_weight_per_year, components\n",
    "\n",
    "def get_linear_regression_df(df):\n",
    "    linreg = [(\n",
    "        label, \n",
    "        stats.linregress(range(len(row)), row.fillna(0).to_list())\n",
    "    ) for label, row in df.T.iterrows()]\n",
    "    \n",
    "    number_of_years = len(df.T.columns)\n",
    "\n",
    "    linreg_df = pd.DataFrame([\n",
    "        dict(\n",
    "            label=label, \n",
    "            intercept=d.intercept, \n",
    "            slope=d.slope, \n",
    "            rvalue=d.rvalue, \n",
    "            r2value=d.rvalue**2, \n",
    "            pvalue=d.pvalue, \n",
    "            stderr=d.stderr\n",
    "        ) \n",
    "        for label, d in linreg\n",
    "    ])\n",
    "    linreg_df = linreg_df.set_index('label')\n",
    "    pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "    linreg_df['size_mean'] =  df.fillna(0).mean()\n",
    "    linreg_df['slope_rel'] = linreg_df.slope / linreg_df.size_mean\n",
    "    linreg_df['last_year_value'] = linreg_df.intercept + linreg_df.slope * (number_of_years - 1)\n",
    "    return linreg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_func(value, tick_number):\n",
    "        if value == 0:\n",
    "            return '0.0'\n",
    "        return f'{value:.1e}'.replace('e+0', 'e')\n",
    "    \n",
    "\n",
    "def plot_community_development(\n",
    "    config_str, dataset, threshold, name, \n",
    "    selected_clusters=10, colors=None, \n",
    "    most_growing_labels=None, hue_order=None,\n",
    "    show_manual_labels=True\n",
    "):\n",
    "    # Load Graph\n",
    "    global G\n",
    "    G = nx.read_gpickle(\n",
    "        path=f'../../legal-networks-data/{dataset.lower()}/13_cluster_evolution_graph/all_{config_str}.gpickle.gz',\n",
    "    )\n",
    "\n",
    "    # Select weights\n",
    "    nx.set_node_attributes(G, nx.get_node_attributes(G, 'tokens_n'), 'weight')\n",
    "    nx.set_edge_attributes(G, nx.get_edge_attributes(G, 'tokens_n'), 'weight')\n",
    "    \n",
    "    H = filter_edges(G, threshold)\n",
    "    \n",
    "\n",
    "    component_weight_per_year, components = get_connected_components_per_year(H)\n",
    "\n",
    "    # Format numbers\n",
    "    df = pd.DataFrame(component_weight_per_year).T.sort_index()\n",
    "    df.columns = [\n",
    "        sorted(nodes_set, key=lambda n: (H.nodes[n][\"tokens_n\"], n))[-1]\n",
    "        for nodes_set in components\n",
    "    ]\n",
    "    \n",
    "    # Setup cluster filter\n",
    "    if type(selected_clusters) is int:\n",
    "        selected_clusters = df.columns[:selected_clusters]\n",
    "        selected_cluster_labels = None\n",
    "    elif type(selected_clusters) is dict:\n",
    "        selected_cluster_labels = selected_clusters\n",
    "        selected_clusters = list(selected_clusters.keys())\n",
    "    elif type(selected_clusters) is list:\n",
    "        selected_cluster_labels = None\n",
    "    else:\n",
    "        raise Exception('Wrong selected_clusters type')\n",
    "    try:\n",
    "        df_selected = df.loc[:,selected_clusters]\n",
    "    except KeyError :\n",
    "        print('Missing:', sorted(set(selected_clusters) - set(df.columns)))\n",
    "        raise\n",
    "        \n",
    "    # Calculate growth of selected clusters\n",
    "    growth_selected = df_selected.iloc[-1].sum() - df_selected.iloc[0].sum()\n",
    "    print('Selected growth (abs.):', growth_selected)\n",
    "    growth_total = df.iloc[-1].sum() - df.iloc[0].sum()\n",
    "    print('Total growth (abs.):', growth_total)\n",
    "    print('Selected growth (rel.):', growth_selected/growth_total)\n",
    "    \n",
    "    selected_size_ratio_df = df_selected.T.sum() / df.T.sum()\n",
    "    print('Selected sizes per year statistics:')\n",
    "    print(selected_size_ratio_df.describe())\n",
    "    \n",
    "    # Convert data into long format (for seaborn)\n",
    "    global df_melt\n",
    "    df_melt = pd.melt(df_selected.reset_index(), id_vars=['index'])\n",
    "    df_melt.columns = ['Year', 'Cluster', 'Tokens']\n",
    "    \n",
    "    # Hue order\n",
    "    leading_clusters = [c[0] for c in cluster_families(G, 0.15)]\n",
    "    if not hue_order:\n",
    "        hue_order = sorted(\n",
    "            df_melt.Cluster.unique(),\n",
    "            key=lambda x: leading_clusters.index(x)\n",
    "        )\n",
    "\n",
    "    # Plot scatter\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    ax = sns.scatterplot(\n",
    "        x='Year', \n",
    "        y='Tokens', \n",
    "        hue='Cluster',\n",
    "        hue_order=hue_order,\n",
    "        data=df_melt, \n",
    "        palette=cluster_family_colors(dataset) if colors is None else colors,\n",
    "    )\n",
    "    ax.set_xticklabels(df.T.columns, rotation=90)\n",
    "    \n",
    "    # Regression\n",
    "    linreg_df = get_linear_regression_df(df)\n",
    "    line_df = pd.DataFrame([\n",
    "        {\n",
    "            'label': label,\n",
    "            df.T.columns[0]: row.intercept,\n",
    "            df.T.columns[-1]: row.intercept + row.slope * (len(df.T.columns) - 1)\n",
    "        }\n",
    "        for label, row in linreg_df.iterrows()\n",
    "    ])\n",
    "    line_df = line_df.set_index('label')\n",
    "    \n",
    "    line_df_selected = line_df.loc[selected_clusters]\n",
    "    line_df_selected.index.names = ['label']\n",
    "    \n",
    "    # Convert data into long format (for seaborn)\n",
    "    df_line_melt = pd.melt(line_df_selected.reset_index(), id_vars=['label'])\n",
    "    df_line_melt.columns = ['Cluster', 'Year', 'Tokens']\n",
    "        \n",
    "    # Plot lines\n",
    "    sns.lineplot(\n",
    "        x='Year', \n",
    "        y='Tokens', \n",
    "        hue='Cluster', \n",
    "        hue_order=hue_order,\n",
    "        data=df_line_melt, \n",
    "        palette=cluster_family_colors(dataset) if colors is None else colors,\n",
    "        legend=False,\n",
    "    )\n",
    "        \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    handle_dict = {label: handle for handle, label in zip(handles, labels)}\n",
    "    labels = line_df_selected.sort_values(line_df_selected.columns[-1], ascending=False).index.to_list()\n",
    "    handles = [handle_dict[l] for l in labels]\n",
    "\n",
    "    manual_labels = get_manual_labels(dataset)\n",
    "    labels = [f'{l.split(\"_\")[-1]} in {l.split(\"_\")[0][:4]}' for l in labels]\n",
    "    if show_manual_labels:\n",
    "        labels = [\n",
    "            f'{manual_labels[l]} â€“ {l}' if l in manual_labels else l\n",
    "            for l in labels\n",
    "        ]\n",
    "    \n",
    "    legend = ax.legend(handles, labels, loc='upper center', \n",
    "                bbox_to_anchor=(0.5, -0.15), frameon=False, ncol=(1 if show_manual_labels else 4))\n",
    "    ax.set_xticklabels(range(1994,2019))\n",
    "    plt.ylim(0,3000000 if dataset == 'us' else 900000) \n",
    "\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(format_func))\n",
    "    \n",
    "    plt.savefig(\n",
    "        f'../graphics/cluster-evolution-size-dynamics-{dataset.lower()}-{config_str}-{name}.pdf', \n",
    "        bbox_extra_artists=(legend,), \n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    \n",
    "    linreg_df_selected = linreg_df.loc[selected_clusters]\n",
    "    return linreg_df_selected, components, hue_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_slope_to_size(linreg_df_top, dataset, name):\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    regplt = sns.regplot(linreg_df_top.slope, linreg_df_top.size_mean)\n",
    "    regplt.set(\n",
    "        ylim=(0, None),\n",
    "        xlabel='Slope',\n",
    "        ylabel='Mean size'\n",
    "    )\n",
    "    regplt.xaxis.set_major_formatter(plt.FuncFormatter(format_func))\n",
    "    regplt.yaxis.set_major_formatter(plt.FuncFormatter(format_func))\n",
    "\n",
    "\n",
    "    print(stats.linregress(\n",
    "        linreg_df_top.slope.fillna(0), \n",
    "        linreg_df_top.size_mean.fillna(0),\n",
    "    ))\n",
    "    plt.savefig(\n",
    "        f'../graphics/cluster-evolution-slope-size-regression-{dataset.lower()}-{name}.pdf', \n",
    "    )\n",
    "    \n",
    "\n",
    "def analyse_slope_rel_to_size(linreg_df_top):\n",
    "    ax = sns.regplot(linreg_df_top.slope_rel, linreg_df_top.size_mean)\n",
    "    print(stats.linregress(\n",
    "        linreg_df_top.slope_rel.fillna(0), \n",
    "        linreg_df_top.size_mean.fillna(0)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### US regression plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 20 for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_df_top_us, components, hue_order_us = plot_community_development(\n",
    "    config_str='0-0_1-0_-1_a-infomap_n100_m1-0_s0_c1000', \n",
    "    dataset='us', \n",
    "    threshold=0.15,\n",
    "    name='top20',\n",
    "    selected_clusters=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_slope_to_size(linreg_df_top_us, 'us', 'top20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_df_top_us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Selected for print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "linreg_df_top, components, _ = plot_community_development(\n",
    "    config_str='0-0_1-0_-1_a-infomap_n100_m1-0_s0_c1000', \n",
    "    dataset='us', \n",
    "    threshold=0.15,\n",
    "    name='selected',\n",
    "    selected_clusters={\n",
    "        # Growing\n",
    "        '2015_3': 'Public health and social welfare', \n",
    "        '2010_0': 'Financial regulation',\n",
    "        '2011_3': 'Student loans and economic support',\n",
    "        '2015_11': 'Tax',\n",
    "        '2015_4': 'Foreign assistance',\n",
    "        # Stagnating\n",
    "        '2009_8': 'Public housing',\n",
    "        '1995_3': 'Agriculture',\n",
    "    },\n",
    "    most_growing_labels=['2015_3', '2010_0', '2011_3', '2015_11', '2015_4'],\n",
    "    hue_order=hue_order_us,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "analyse_slope_to_size(linreg_df_top, 'us', 'selected')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DE regression plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 20 for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_df_top_de, components, hue_order_de = plot_community_development(\n",
    "    config_str='0-0_1-0_-1_a-infomap_n100_m1-0_s0_c1000', \n",
    "    dataset='de', \n",
    "    threshold=0.15,\n",
    "    selected_clusters=20,\n",
    "    name='top20'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_slope_to_size(linreg_df_top_de, 'de', 'top20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_df_top_de.sort_values('slope', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_df_top_de.sort_values('slope')[['slope']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selected for print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_df_top, components, _ = plot_community_development(\n",
    "    config_str='0-0_1-0_-1_a-infomap_n100_m1-0_s0_c1000', \n",
    "    dataset='de', \n",
    "    threshold=0.15,\n",
    "    name='selected',\n",
    "    selected_clusters={\n",
    "        # Growing\n",
    "        '2018-01-01_2': 'Social welfare',\n",
    "        '2017-01-01_8': 'Financial regulation',\n",
    "        '2018-01-01_34': 'Renewable energy',\n",
    "        '2018-01-01_0': 'Tax',\n",
    "        '2015-01-01_15': 'Corporations',\n",
    "        # Stagnating\n",
    "        '2000-01-01_16': 'Reparations',\n",
    "        '2011-01-01_21': 'Inheritance',\n",
    "    },\n",
    "    most_growing_labels=['2018-01-01_2', '2017-01-01_8', '2018-01-01_34', '2018-01-01_0', '2015-01-01_15'],\n",
    "    hue_order=hue_order_de\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_slope_to_size(linreg_df_top, 'de', 'selected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_df_top.sort_values('slope')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table with regression values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_df_top_us.sort_values('last_year_value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_linreg_df(df, country_code):\n",
    "    df = df.sort_values('last_year_value', ascending=False)\n",
    "    df.index = [f'{l.split(\"_\")[-1]} in {l.split(\"_\")[0][:4]}' for l in df.index]\n",
    "    df = df.reset_index()\n",
    "    df = df[[\n",
    "        'index', \n",
    "        'slope', \n",
    "        'intercept', \n",
    "        'pvalue', \n",
    "        'rvalue',  \n",
    "        'r2value',  \n",
    "        'stderr', \n",
    "        'size_mean'\n",
    "    ]]\n",
    "    df.columns = [\n",
    "        'Cluster\\\\\\\\family', \n",
    "        'Slope', 'Intercept', \n",
    "        'P-value', \n",
    "        'Correlation\\\\\\\\coefficient ($r$)', \n",
    "        '$r^2$', \n",
    "        'Standard\\\\\\\\error', \n",
    "        'Mean value'\n",
    "    ]\n",
    "    df['Country\\\\\\\\code'] = country_code\n",
    "    df = df.set_index(['Country\\\\\\\\code', 'Cluster\\\\\\\\family'])\n",
    "    return df\n",
    "\n",
    "latex_df = pd.concat([\n",
    "    save_linreg_df(linreg_df_top_us, 'US'),\n",
    "    save_linreg_df(linreg_df_top_de, 'DE')\n",
    "]).sort_values(['Country\\\\\\\\code', 'Slope'], ascending=False)\n",
    "cols =  [\n",
    "    '\\multicolumn{1}{p{14mm}}{\\centering ' + c + '}' \n",
    "    for c in latex_df.columns\n",
    "]\n",
    "cols[0] = cols[0].replace('14mm', '18mm')\n",
    "cols[1] = cols[1].replace('14mm', '18mm')\n",
    "cols[2] = cols[2].replace('14mm', '10mm')\n",
    "cols[3] = cols[3].replace('14mm', '16mm')\n",
    "cols[4] = cols[4].replace('14mm', '10mm')\n",
    "cols[5] = cols[5].replace('14mm', '16mm')\n",
    "cols[6] = cols[6].replace('14mm', '18mm')\n",
    "\n",
    "\n",
    "latex_df.columns = cols\n",
    "\n",
    "latex_df.index.names = [\n",
    "    '\\multicolumn{1}{p{14mm}}{\\centering ' + c + '}' \n",
    "    for c in latex_df.index.names\n",
    "]\n",
    "\n",
    "with open(f'../graphics/cluster_family_growth_stats.tex', 'w') as f:\n",
    "    latex_df.to_latex(f, escape=False, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect other configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ['us', 'de']:\n",
    "    for config_str in ['0-0_1-0_-1_a-infomap_m1-0_s0_c1000'] + [\n",
    "        f'0-0_1-0_-1_a-infomap_n{runs}_m1-0_s0_c1000' for runs in list(range(60,150+1,10)) + [200]\n",
    "    ]:\n",
    "        print('starting', config_str)\n",
    "        if config_str != f'0-0_1-0_-1_a-infomap_n100_m1-0_s0_c1000':\n",
    "            # plotted already above\n",
    "            plot_community_development(\n",
    "                config_str, \n",
    "                dataset, \n",
    "                threshold=0.15,\n",
    "                name='top20',\n",
    "                selected_clusters=20,\n",
    "                show_manual_labels=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### End\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}